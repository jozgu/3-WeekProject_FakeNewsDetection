{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp38-cp38-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\alexander\\anaconda3\\lib\\site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: Cython==0.29.23 in c:\\users\\alexander\\anaconda3\\lib\\site-packages (from gensim) (0.29.23)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\alexander\\anaconda3\\lib\\site-packages (from gensim) (1.20.1)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.1.2 smart-open-5.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries to build Word2Vec model, and load Newsgroups data\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phraser, Phrases\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der er  44898  artikler i datafilen\n",
      "Der er  44218  artikler i corpus\n",
      "Forskellen er 680 artikler\n"
     ]
    }
   ],
   "source": [
    "#Import data\n",
    "df1 = pd.read_csv(\"True.csv\")\n",
    "data1 = df1[\"text\"]\n",
    "df2 = pd.read_csv(\"Fake.csv\")\n",
    "data2 = df2[\"text\"]\n",
    "data = pd.concat([data1, data2], ignore_index=True)\n",
    "y = np.hstack((np.zeros(len(data1)), np.ones(len(data2))))\n",
    "\n",
    "# Remove Special Characters and append to corpus\n",
    "\n",
    "dumb_files = []\n",
    "corpus = []\n",
    "for i, text in enumerate(data):\n",
    "    try:\n",
    "        text_mod = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "        text_mod = text_mod.lower()\n",
    "        text_mod = text_mod.split()\n",
    "\n",
    "        filt = [w for w in text_mod if len(w) > 1]\n",
    "        if len(filt) > 3:\n",
    "            corpus.append(filt)\n",
    "        else:\n",
    "            dumb_files.append(i)\n",
    "        \n",
    "    except TypeError:\n",
    "        dumb_files.append(i)\n",
    "\n",
    "print('Der er ',len(data),' artikler i datafilen')\n",
    "print('Der er ',len(corpus),' artikler i corpus')\n",
    "print('Forskellen er', len(data)-len(corpus), 'artikler' )\n",
    "\n",
    "y = np.delete(y, dumb_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in corpus:\n",
    "    if len(i) < 3:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=115465, vector_size=100, alpha=0.025)\n",
      "Word2Vec(vocab=115465, vector_size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "model = Word2Vec(corpus, min_count=0)\n",
    "\n",
    "#summarize the loaded model\n",
    "print(model)\n",
    "\n",
    "#summarize vocabulary into list\n",
    "words = list(model.wv.index_to_key)\n",
    "# print(words)\n",
    "\n",
    "#access vector for one word\n",
    "# print(model.wv['trump'])\n",
    "# print(model.wv.most_similar('fish', topn=10))\n",
    "\n",
    "#save model\n",
    "model.save('model.selftrained')\n",
    "\n",
    "#load model\n",
    "new_model = Word2Vec.load('model.selftrained')\n",
    "print(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('he', 0.7037044763565063), ('that', 0.6904121041297913), ('this', 0.6482501029968262), ('something', 0.6327779293060303), ('but', 0.6250712871551514), ('she', 0.6169869303703308), ('really', 0.6001038551330566), ('simply', 0.5811920762062073), ('anything', 0.5782747268676758), ('what', 0.5712040066719055)]\n"
     ]
    }
   ],
   "source": [
    "word_to_test = 'it'\n",
    "print(model.wv.most_similar(word_to_test,topn=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_length = 100\n",
    "art_matrix = np.zeros((len(corpus), vector_length))\n",
    "\n",
    "for i, text in enumerate(corpus):\n",
    "    vect = [model.wv[w] for w in text]\n",
    "    x = np.mean(vect, axis=0)\n",
    "    art_matrix[i] = x\n",
    "\n",
    "# print(art_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "x = np.argwhere(np.isnan(art_matrix))\n",
    "print(x)\n",
    "row = 0\n",
    "for i in x[:, 0]:\n",
    "    if i > row:\n",
    "        # print(corpus[i])\n",
    "        row = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average cross-validation score: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "first_scores = cross_val_score(log_reg, art_matrix, y, cv=5)\n",
    "print(\"Average cross-validation score: {:.2f}\".format(first_scores.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "30520a5b9d041d48c1c10fddcc9b5b0577fb068abc6b18e155e4ae8efbc7d2a3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
